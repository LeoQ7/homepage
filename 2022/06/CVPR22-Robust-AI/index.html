<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>CVPR 2022 Robust Models towards Openworld Classification Competition Writeup - Qi Qin</title><meta name=Description content="Writeup for CVPR 2022 Robust Models towards Openworld Classification Competition"><meta property="og:title" content="CVPR 2022 Robust Models towards Openworld Classification Competition Writeup"><meta property="og:description" content="Writeup for CVPR 2022 Robust Models towards Openworld Classification Competition"><meta property="og:type" content="article"><meta property="og:url" content="https://leoq7.com/2022/06/CVPR22-Robust-AI/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-06-02T17:55:28+08:00"><meta property="article:modified_time" content="2022-06-02T17:55:28+08:00"><meta property="og:site_name" content="Qi Qin"><meta name=twitter:card content="summary"><meta name=twitter:title content="CVPR 2022 Robust Models towards Openworld Classification Competition Writeup"><meta name=twitter:description content="Writeup for CVPR 2022 Robust Models towards Openworld Classification Competition"><meta name=application-name content="Qi Qin"><meta name=apple-mobile-web-app-title content="Qi Qin"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://leoq7.com/2022/06/CVPR22-Robust-AI/><link rel=next href=https://leoq7.com/2022/12/CTF-Movement-Aptos/><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"CVPR 2022 Robust Models towards Openworld Classification Competition Writeup","inLanguage":"en-us","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/leoq7.com\/2022\/06\/CVPR22-Robust-AI\/"},"genre":"posts","keywords":"AI, CVPR","wordcount":1220,"url":"https:\/\/leoq7.com\/2022\/06\/CVPR22-Robust-AI\/","datePublished":"2022-06-02T17:55:28+08:00","dateModified":"2022-06-02T17:55:28+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"Qi Qin"},"description":"Writeup for CVPR 2022 Robust Models towards Openworld Classification Competition"}</script></head><body data-header-desktop=fixed data-header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem('theme')?localStorage.getItem('theme')==='dark':'auto'==='auto'?window.matchMedia('(prefers-color-scheme: dark)').matches:'auto'==='dark')&&document.body.setAttribute('theme','dark')</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="Qi Qin">Qi Qin</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/>About Me </a><a class=menu-item href=/publications/>Publications </a><a class=menu-item href=/contact/>Contact </a><a class=menu-item href=/posts/>Blogs </a><a class=menu-item href=/links/>Links </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop><input type=text placeholder="Search titles or contents..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i></a>
<span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span>
</span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="Qi Qin">Qi Qin</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="Search titles or contents..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i></a>
<span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><a class=menu-item href=/ title>About Me</a><a class=menu-item href=/publications/ title>Publications</a><a class=menu-item href=/contact/ title>Contact</a><a class=menu-item href=/posts/ title>Blogs</a><a class=menu-item href=/links/ title>Links</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">CVPR 2022 Robust Models towards Openworld Classification Competition Writeup</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://leoq7.com title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>Qi Qin</a></span>&nbsp;<span class=post-category>included in <a href=/categories/AI/><i class="far fa-folder fa-fw" aria-hidden=true></i>AI</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime=2022-06-02>2022-06-02</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;1220 words&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;6 minutes&nbsp;</div></div><div class="details toc" id=toc-static data-kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#competition-analysis>Competition Analysis</a></li><li><a href=#qualifying-round-exploit-a-information-leak>Qualifying Round: Exploit a Information Leak</a></li><li><a href=#final-round-unique-characteristics-of-adversarial-examples>Final Round: Unique Characteristics of Adversarial Examples</a></li><li><a href=#ablation-study>Ablation Study</a></li><li><a href=#reference>Reference</a></li></ul></nav></div></div><div class=content id=content><p>Art of Robustness Workshop on CVPR 2022 and SenseTime jointly organized a Robust AI Competition. This competition focuses on classification task defense and open set defense against adversarial attacks. Our team hit the top1 in the qualifying round and top 5 in the final round of the competition.</p><h2 id=competition-analysis>Competition Analysis</h2><p>During the competition, we mainly focused on <code>Track II: Open Set Defense</code>.</p><blockquote><p>Most defense methods aim to build robust model in the closed set (e.g., under fixed datasets with constrained perturbation types and budgets). However, in the real-world scenario, adversaries would bring more harms and challenges to the deep learning-based applications by generating unrestricted attacks, such as large and visible noises, perturbed images with unseen labels, etc.</p><p>To accelerate the research on building robust models in the open set, we organize this challenge track. Participants are encouraged to develop a robust detector that could distinguish clean examples from perturbed ones on unseen noises and classes by training on a limited-scale dataset.</p></blockquote><p>In essence, it&rsquo;s an adversarial example detection competition that requires participants to determine whether a input image is a benign sample or an adversarial example. In this area, our research center (<a href=https://ssc.sist.shanghaitech.edu.cn/ target=_blank rel="noopener noreffer">SSC</a>) has published two related papers <a href=#reference rel>[1]</a><a href=#reference rel>[2]</a>, both of which use the similar idea that different kinds of adversarial samples will have unique characteristics.</p><p>In <a href=#reference rel>[1]</a>, the authors proposed <code>Magnet</code>, which use an autoencoder to learn the manifold of normal examples. <code>MagNet</code> reconstructs adversarial examples by moving them towards the manifold. Therefore, adversarial examples with large perturbation could be detected directly based on the reconstruction error. If the input has a small perturbation, the noise can be eliminated and changed to a benign sample after decoding. In <a href=#reference rel>[2]</a>, robustness is used to filter out those samples that just cross the decision boundary, followed by other methods to filter out those large perturbation samples. We adopted a similar strategy in the final round.</p><h2 id=qualifying-round-exploit-a-information-leak>Qualifying Round: Exploit a Information Leak</h2><p>In the qualifying round, we unexpectedly found that the file sizes of benign samples tended to be smaller while those of adversarial samples tended to be larger by sorting the images according to the file sizes.</p><p>Initially, our conjecture was that due to the compression algorithm of <code>PNG</code>, the adversarial perturbation corrupts the locality smoothness of the pixels to some extent, which subsequently affects the effectiveness of <code>PNG</code> compression. However, after deeper analysis we found that the organizers introduced a huge information leak when saving the images: although all images have the suffix of <code>.png</code>, only the file type of the adversarial samples is actually <code>PNG</code>, and the actual file type of most images is <code>JPEG</code>, which are almost all benign samples.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash>❯ exa <span class=p>|</span> wc -l
<span class=m>5000</span>
❯ file *.png <span class=p>|</span> grep JPEG <span class=p>|</span> wc -l
<span class=m>4627</span>
❯ file 0.png
0.png: JPEG image data, JFIF standard 1.01, aspect ratio, density 1x1, segment length 16, baseline, precision 8, 224x224, components <span class=m>3</span>
❯ file 35.png
35.png: PNG image data, <span class=m>224</span> x 224, 8-bit/color RGB, non-interlaced
</code></pre></td></tr></table></div></div><p>By leveraging this information leakage, we achieved nearly 100% accuracy and became the top qualifier.</p><h2 id=final-round-unique-characteristics-of-adversarial-examples>Final Round: Unique Characteristics of Adversarial Examples</h2><p>Unfortunately, the authors realized the information leak and fixed it in the final round. Therefore, we chose to use the strategy similar to the previous two papers where we first classify the potential adversarial examples and use different detection methods for different types of adversarial examples. We divided the adversarial examples into four categories, namely <code>Adversarial Patch</code> <a href=#reference rel>[3]</a>, <code>Square Attack</code> <a href=#reference rel>[4]</a>, <code>Universial Adversial Patch (UAP)</code> <a href=#reference rel>[5]</a> or <code>Fast Gradient Sign Method (FGSM)</code> <a href=#reference rel>[6]</a>, and others. We locally constructed a dataset of about 2,000 adversarial examples and 18,000 benign samples, which consists of about 250 images of Patch, 250 images of Square, 500 UAP or FGSM images and the other 1,000 images generated by adversarial attacks that seek to minimize the $L_2$ perturbations.</p><p>For Patch samples, we trained a autoencoder and used the reconstruction error of $L_{inf}$ distance as a judgment metric. As the patch adversarial examples have a significant noise in a region about 20*20, the reconstruction error tends to be close to 1 for that type of adversarial examples, while the reconstruction error for benign samples is closer to 0.</p><center class=half><img src=./patch.png width=30%>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src=./patch2.png width=30%></center><p>For Square samples, a distinctive feature is the presence of some colored vertical stripes and rectangles visible to the naked eye on the picture. And we noted that the <code>H</code> channel has significant vertical stripes after converting the color space to <code>HSV</code> space. Therefore, we further calculated the difference of the sum of each column. The larger the difference indicates that the corresponding image is more likely to be a Square sample.</p><center class=half><img src=./square.png width=30%>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src=./square2.png width=30%></center><p>For UAP and FGSM samples, they are characterized by the presence of some noise or continuous texture on the image. To make these features more prominent, we used a <code>Laplacian</code> operator to enhance the edges and subsequently enhance the effect of the noise. Similar to square samples, we observed that the noise in the <code>V</code> channel is more pronounced after transforming the images onto <code>HSV</code> space. To measure the amount of noise, we computed histograms for the V channel. The more the curve on the histograms plot is skewed in the positive direction of the x-axis, the more noisy the image is, and the more likely it is a UAP or FGSM sample. Therefore, we constructed an expression to determine the shape of the histogram curve and subsequently whether the image is an adversarial sample.</p><center class=half><img src=./uap.png width=30%>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src=./uap2.png width=30%></center><p>For other samples, we directly utilize the metrics used for square detection as the organizer will find out the best threshold that yields the highest <code>F1-Score</code>, rather than requiring us to make a binary classification. Our intention was to use the model output or sample robustness to make judgments, just as [2], but unfortunately the organizers of this competition did not provide model information, so these adversarial examples may have poor transferability against our locally trained model.</p><center class=half><img src=./benign.png width=30%>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src=./abnormal.png width=30%><p align=center style=font-size:12px>Distance to decision boundary of a blue normal example and brown adversarial example.</p></center><h2 id=ablation-study>Ablation Study</h2><p>We constructed the dataset locally and evaluated our method.</p><ul><li><p>For Patch attack, the local F1 score on all adversarial examples is <code>0.2792</code>, where the precision is <code>0.9829</code> and the recall is <code>0.1627</code>. The F1 score for Patch is <code>0.9812</code>, where the recall of Patch adv is <code>0.9795</code>.</p></li><li><p>For Square attack, the local F1 score on all adversarial examples is <code>0.2729</code>, where the precision is <code>0.932</code> and the recall is <code>0.1609</code>. The F1 score for Sqaure is <code>0.8007</code>, where the recall of Square adv is <code>0.8614</code>.</p></li><li><p>For UAP or FGSM attack, the local F1 score on all adversarial examples is <code>0.478</code>, where the precision is <code>0.8483</code> and the recall is <code>0.3328</code>. The F1 score for UAP or FGSM is <code>0.8711</code>, where the recall of UAP or FGSM adv is <code>0.8951</code>.</p></li></ul><h2 id=reference>Reference</h2><p>[1] Meng, Dongyu, and Chen, Hao. &ldquo;Magnet: a two-pronged defense against adversarial examples.&rdquo; CCS 2017.</p><p>[2] Zhao, Zhe, et al. &ldquo;Attack as defense: characterizing adversarial examples using robustness.&rdquo; ISSTA 2021.</p><p>[3] Karmon, Danny, et al. &ldquo;LaVAN: Localized and Visible Adversarial Noise.&rdquo; ICML 2018.</p><p>[4] Andriushchenko, Maksym, et al. &ldquo;Square Attack: A Query-Efficient Black-Box Adversarial Attack via Random Search.&rdquo; ECCV 2020.</p><p>[5] Moosavi-Dezfooli, Seyed-Mohsen, et al. &ldquo;Universal adversarial perturbations.&rdquo; arXiv 2016.</p><p>[6] Goodfellow, Ian J, et al. &ldquo;Explaining and harnessing adversarial examples.&rdquo; arXiv 2014.</p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2022-06-02</span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=https://leoq7.com/2022/06/CVPR22-Robust-AI/ data-title="CVPR 2022 Robust Models towards Openworld Classification Competition Writeup" data-via=LeoQ7_ data-hashtags=AI,CVPR><i class="fab fa-twitter fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://leoq7.com/2022/06/CVPR22-Robust-AI/ data-hashtag=AI><i class="fab fa-facebook-square fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Hacker News" data-sharer=hackernews data-url=https://leoq7.com/2022/06/CVPR22-Robust-AI/ data-title="CVPR 2022 Robust Models towards Openworld Classification Competition Writeup"><i class="fab fa-hacker-news fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Line" data-sharer=line data-url=https://leoq7.com/2022/06/CVPR22-Robust-AI/ data-title="CVPR 2022 Robust Models towards Openworld Classification Competition Writeup"><i data-svg-src=https://cdn.jsdelivr.net/npm/simple-icons@6.20.0/icons/line.svg aria-hidden=true></i></a><a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=https://leoq7.com/2022/06/CVPR22-Robust-AI/ data-title="CVPR 2022 Robust Models towards Openworld Classification Competition Writeup"><i class="fab fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=/tags/AI/>AI</a>,&nbsp;<a href=/tags/CVPR/>CVPR</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/2022/12/CTF-Movement-Aptos/ class=next rel=next title="CTF MOVEment with Aptos Dec 2022 Writeup">CTF MOVEment with Aptos Dec 2022 Writeup<i class="fas fa-angle-right fa-fw" aria-hidden=true></i></a></div></div><div id=comments><div id=utterances class=comment></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://utteranc.es/>Utterances</a>.</noscript></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork><i class="far fa-copyright fa-fw" aria-hidden=true></i><span itemprop=copyrightYear>2020 - 2023</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank>Qi Qin</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/lightgallery@2.4.0/css/lightgallery-bundle.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css><script type=text/javascript src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.1/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lightgallery@2.4.0/lightgallery.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lightgallery@2.4.0/plugins/thumbnail/lg-thumbnail.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lightgallery@2.4.0/plugins/zoom/lg-zoom.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js></script><script type=text/javascript>window.config={code:{maxShownLines:50},comment:{utterances:{darkTheme:"github-dark",issueTerm:"og:title",label:"",lightTheme:"github-light",repo:"LeoQ7/LeoQ7-comments"}},lightgallery:!0,math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{highlightTag:"em",lunrIndexURL:"/index.json",maxResultLength:10,noResultsFound:"No results found",snippetLength:30,type:"lunr"}}</script><script type=text/javascript src=/js/theme.min.js></script></body></html>